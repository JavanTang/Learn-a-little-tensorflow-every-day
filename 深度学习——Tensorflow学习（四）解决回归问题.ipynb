{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "深度学习——Tensorflow学习（四）解决回归问题.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JavanTang/Learn-a-little-tensorflow-every-day/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Tensorflow%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%9B%9B%EF%BC%89%E8%A7%A3%E5%86%B3%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "N3nq6bigAoBE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "首先我们先来学习什么是回归？\n",
        "\n",
        "一样请移步 [回归与分类的区别](https://www.zhihu.com/question/21329754/answer/17901883)\n",
        "\n",
        "看完之后，我首先来说说本章具体是做什么？\n",
        "\n",
        "1. 首先来说说tensorflow官方的栗子做一个预测燃料效率的事情。\n",
        "2. 然后我们去Kaggle上面做一个比赛House Prices: Advanced Regression Techniques\n",
        "\n",
        "\n",
        "## 上代码"
      ]
    },
    {
      "metadata": {
        "id": "bbrGul_9Nb-O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use seaborn for pairplot\n",
        "!pip install seaborn\n",
        "!pip install tensorflow==2.0.0-alpha0\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import tensorflow as t\n",
        "from tensorflow import keras as k\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "print(t.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yzef-VQWS9dX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_path = k.utils.get_file(\"auto-mpg.data\", \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "dataset_path\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b787PoBNUgHF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin'] \n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "dataset[:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rI3kpXN2W4bS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上面的数据，我们看完了之后，需要去处理数据：\n",
        "1. 将不完整的数据挑选出来（名词缺省值）\n",
        "2. 将Origin地址，改成ONE-HOT\n",
        "\n",
        "[ONE-HOT相关资料](https://blog.csdn.net/taotiezhengfeng/article/details/73692239)"
      ]
    },
    {
      "metadata": {
        "id": "bBGdoRwGVUCm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 统计缺省值\n",
        "dataset.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_IRrop1Vnv7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 处理这些缺省值，处理缺省值的方式有很多种，比如去掉，取中位数，平均值等等，我们选取的是去掉这些\n",
        "dataset = dataset.dropna()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5uf-C9gTWwWa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "njqhjn6lWy40",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 将ORIGHT转换成ONE-HOT\n",
        "# 这里是官方文档中处理的方式，其实已经有很多封装好了的方法，建议大家在这里可以采取自己的一些方式\n",
        "\n",
        "origin = dataset.pop('Origin')\n",
        "dataset['USA'] = (origin == 1)*1.0\n",
        "dataset['Europe'] = (origin == 2)*1.0\n",
        "dataset['Japan'] = (origin == 3)*1.0\n",
        "dataset.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EbksQ0U_X9Ac",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Pandas分割数据集  如果不是Pandas的数据我们可以参考（三）中使用sklearn进行分割数据集\n",
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j_fGcKLgZcIP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J1rwnNY9ZeRd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# describe 统计数值型数据的特性（数量、平均数、标准差、最小值，最大值）\n",
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop(\"MPG\")\n",
        "\n",
        "# 这里之所以要转置是因为方便之后的矩阵相乘\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6DB0PewabFy7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_labels = train_dataset.pop('MPG')\n",
        "test_labels = test_dataset.pop('MPG')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tEKqQQTdWNma",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mk24aFsudcGb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_stats = train_stats.transpose()\n",
        "def norm(x):\n",
        "  '''\n",
        "  标准化,参考3中有为什么要做标准化的解释\n",
        "  '''\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9PfXoA8QhgGo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "normed_train_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OiDTllEsgV75",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "以上就是数据处理的部分了,下面我们要开始老套路 构建模型、配置模型、训练模型、验证模型。"
      ]
    },
    {
      "metadata": {
        "id": "VjBXgrBXeAf1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 构建模型\n",
        "model = k.Sequential([\n",
        "    layers.Dense(64, activation='relu',input_shape=[len(normed_train_data.keys())]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# 配置模型\n",
        "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pecaxgwTjeVv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 训练模型\n",
        "\n",
        "history = model.fit(normed_train_data, train_labels,epochs=1000, validation_split = 0.2, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-42gB86h2ek3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hist = pd.DataFrame(history.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4y1CjeyMkI5f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history)\n",
        "  hist['epoch'] = list(hist.index+1)\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [MPG]')\n",
        "  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
        "           label='Val Error')\n",
        "  plt.ylim([0,5])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [MPG^2]')\n",
        "  plt.plot(hist['epoch'],hist['mean_squared_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'],hist['val_mean_squared_error'],\n",
        "           label='Train Error')\n",
        "  plt.ylim([0,20])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "  \n",
        "plot_history(history.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "83a7YspX9m4A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "在图中我们发现其实在100轮以后val（验证集）上面基本上没有明细的改进了，而训练集还在继续训练，这个时候我们为了确保它拥有很好的泛化性，我们应该在验证集不在变化的时候就停止训练。\n",
        "\n",
        "这个工作在我们fit函数中就可以直接设置。"
      ]
    },
    {
      "metadata": {
        "id": "P9ZzA6xm-QCx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 重新该块的工作，这里我们和上面的代码就重复了，今后我们会使用函数去build这个模型，以防遇到这种问题我们还需要重写这一块的代码\n",
        "# 构建模型\n",
        "model = k.Sequential([\n",
        "    layers.Dense(64, activation='relu',input_shape=[len(normed_train_data.keys())]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# 配置模型\n",
        "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "\n",
        "\n",
        "# keras 函数回调的APIhttps://keras.io/zh/callbacks/\n",
        "early_stop = k.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "history = model.fit(normed_train_data, train_labels, epochs=1000, validation_split = 0.2, verbose=1, callbacks=[early_stop])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rEEsvLKCAEC6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "上面的因为verbose为1，所以输出了很多繁杂的数据。\n",
        "\n",
        "我们想个办法让它30轮输出一次，我们可以创建一个回调函数\n",
        " [API](https://keras.io/zh/callbacks/)"
      ]
    },
    {
      "metadata": {
        "id": "MTdwq6hSACzF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class PrintLog(k.callbacks.Callback):\n",
        "    def on_train_begin(self, logs):\n",
        "        pass\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "\n",
        "        if epoch % 30 == 0: \n",
        "          print('epoch:',epoch, '\\tlogs:',logs)\n",
        "\n",
        "\n",
        "            \n",
        "model = k.Sequential([\n",
        "    layers.Dense(64, activation='relu',input_shape=[len(normed_train_data.keys())]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# 配置模型\n",
        "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "\n",
        "\n",
        "# keras 函数回调的APIhttps://keras.io/zh/callbacks/\n",
        "early_stop = k.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "history = model.fit(normed_train_data, train_labels, epochs=1000, validation_split = 0.2, verbose=0, callbacks=[PrintLog(),early_stop])\n",
        "plot_history(history.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OJspEa--FHqi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=0)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fuFZNjHUFbfQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(normed_test_data)\n",
        "normed_test_data.head()\n",
        "\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predictions')\n",
        "plt.ylim([0,50])\n",
        "plt.xlim([0,50])\n",
        "\n",
        "_ = plt.plot([-100, 100], [-100, 100])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YLn8MO9kwOf3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "看来真实值与预测值很接近"
      ]
    },
    {
      "metadata": {
        "id": "15kl7UwVwfo-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 不加下面这句话会导致两者维度不一致\n",
        "# https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.ndarray.flatten.html\n",
        "test_predictions = test_predictions.flatten()\n",
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins = 25)\n",
        "\n",
        "plt.xlabel('Prediction Error')\n",
        "_ = plt.ylabel('Count')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-JC-dFj_xlHP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "这个图形不是那么的高斯，当然因为数据的问题导致的。\n",
        "\n",
        "**总结一下：**\n",
        "\n",
        "1. 回归问题可以使用均方差做loss。\n",
        "2. 平均绝对误差是回归的平均标准。\n",
        "3. 在上面我们将数字差别太大的值做了一遍缩放。\n",
        "4. 数据不大的情况我们使用的隐藏层的层数尽量设置小一点，防止过拟合。\n",
        "5. 早期终止可以避免过拟合。\n",
        "\n",
        "\n",
        "练习：[House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
        "\n",
        "这是一个房价预测的比赛,来源于Kaggle.\n",
        "\n",
        "下次更新\n"
      ]
    },
    {
      "metadata": {
        "id": "L1joEkbUb8CN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "1. [Tensorflow官方教程](https://www.tensorflow.org/tutorials/keras/basic_regression#top_of_page)\n",
        "2. [train_dataset.describe介绍](https://blog.csdn.net/j904538808/article/details/80747599)\n",
        "3. [为什么要做标准化](https://www.zhihu.com/question/20467170)"
      ]
    }
  ]
}